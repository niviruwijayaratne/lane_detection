{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Dropout, BatchNormalization, Conv2DTranspose, Flatten\n",
    "from tensorflow.keras.layers import Concatenate, ZeroPadding2D, PReLU\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerUtil:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def init_block(self, inputs, name):\n",
    "        zero_pad = ZeroPadding2D(1)(inputs)\n",
    "        conv_layer = Conv2D(filters = 13, kernel_size = (3,3), strides = 2)(zero_pad)\n",
    "        pool_layer = MaxPool2D(pool_size = (2,2), strides = 2)(inputs)\n",
    "        return Concatenate(axis = 3,name = name)([conv_layer, pool_layer])\n",
    "    \n",
    "    \n",
    "    ##Each bottleneck consist of:\n",
    "    ##Three convolutional layers:\n",
    "        #1x1 regular convolution (for dimensionality reduction)\n",
    "        #Main conv layer either a regular, dilated, of deconv with 3x3 filters\n",
    "        \n",
    "    def bn_prelu(self, inputs):\n",
    "        batch_norm = BatchNormalization()(inputs)\n",
    "        prelu = PReLU()(batch_norm)\n",
    "        return prelu\n",
    "        \n",
    "    def bottleneck_downsample(self, inputs, down_filter, ):\n",
    "        print(inputs.shape)\n",
    "        dim_reduction = Conv2D(filters = filters, kernel_size = (2,2), strides = (2,2), padding = 'same')(inputs)\n",
    "        print(dim_reduction.shape)\n",
    "        prelu1 = self.bn_prelu(dim_reduction)\n",
    "        \n",
    "        max_pool = MaxPool2D(pool_size = 2, strides = (2,2))(inputs)\n",
    "#         print(max_pool.shape)\n",
    "        \n",
    "        ##assuming downsampling conv is a regular convolution???\n",
    "        main_conv = Conv2D(filters = filters, kernel_size = (3,3), padding = 'same')(prelu1)\n",
    "        prelu2 = self.bn_prelu(main_conv)\n",
    "        \n",
    "        dim_expansion = Conv2D(filters = filters, kernel_size = (1,1), padding = 'same')(prelu2)\n",
    "        prelu3 = self.bn_prelu(dim_expansion)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return prelu2\n",
    "\n",
    "class ENet:\n",
    "    def __init__(self):\n",
    "        self.helper = LayerUtil()\n",
    "    \n",
    "    def build_model(self):\n",
    "        inputs = Input(shape=(512, 512, 3))\n",
    "        concat = self.helper.init_block(inputs, 'init_block')\n",
    "#         print(concat.shape)\n",
    "        bottleneck1 = self.helper.bottleneck_downsample(concat, 64)\n",
    "        model = Model(inputs, bottleneck1)\n",
    "        return model\n",
    "    def compile_model():\n",
    "        pass\n",
    "    \n",
    "    def train_model():\n",
    "        pass\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 16)\n",
      "(None, 128, 128, 64)\n"
     ]
    }
   ],
   "source": [
    "enet = ENet().build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_43\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_42 (InputLayer)           [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPadding2 (None, 514, 514, 3)  0           input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 256, 256, 13) 364         zero_padding2d_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling2D) (None, 256, 256, 3)  0           input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "init_block (Concatenate)        (None, 256, 256, 16) 0           conv2d_60[0][0]                  \n",
      "                                                                 max_pooling2d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 128, 128, 64) 4160        init_block[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 64) 256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_14 (PReLU)              (None, 128, 128, 64) 1048576     batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 128, 128, 64) 36928       p_re_lu_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 64) 256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_15 (PReLU)              (None, 128, 128, 64) 1048576     batch_normalization_16[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 2,139,116\n",
      "Trainable params: 2,138,860\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
